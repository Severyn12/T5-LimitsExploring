# T5-Limits Exploring
***
## Abstract
”Large language models (LLMs) have taken the world by storm in recent years. These models, such
as OpenAI’s GPT-3, are trained on massive amounts of data and can generate human-like language,
answer questions, and even write articles and stories.

The speed at which LLMs are spreading is remarkable. They are used in various applications,
from language translation and content generation to customer service and chatbots. Companies and
organizations across different industries are investing heavily in LLMs to improve their services, boost
their productivity, and gain a competitive edge.”

Not surprisingly, even this piece of text was generated by ChatGPT. The area of Natural Language
processing will only gain momentum in the future. It is important to understand how do such models
work under the hood, what are their limitations, may it be dangerous to give lives for them and make
it accessible to all people.
***
## Aim

During our research we dived deeper into this topic and tried to fine-tune T5 model for specific NLP tasks. We explored its performance and limits across several datasets, focusing particularly on text summarization and question answering tasks.
***
## Data

For our experiments, we mainly used two publicly available datasets, which cover a wide range of topics, ensuring diversity and enabling the evaluation of models across different domains.

For the summarization task, we used [Medium Articles](https://www.kaggle.com/datasets/fabiochiusano/medium-articles) dataset that contains 190K articles from Medium and corresponding titles. Each sample there contains information about the text in the article, its author, publication date, tags, and title. We selected text and title properties for our further research. 

On the other hand, for the question-answering task, we worked with the [SQUAD](https://www.kaggle.com/datasets/stanfordu/stanford-question-answering-dataset) dataset, which was created by Stanford University and consists of question-answer pairs derived from Wikipedia articles. Each entry in the dataset includes the following fields: title, context, question, and answer. For our specific research, we focused on the context, question, and answer fields.
***
## Model's architecture
T5 (Text-To-Text Transfer Transformer) is a state-of-the-art language model, which is based on the Transformer architecture and designed to perform various natural language processing (NLP) tasks using a unified framework. T5 is a "text-to-text" model, which means it converts input text into output text, making it highly versatile.

Unlike previous models that were trained for specific tasks, T5 is trained in a "pretraining-finetuning" paradigm. During pretraining, T5 is trained on a large corpus of publicly available text from the internet, where it learns to generate target text given input text. And then T5 is fine-tuned on specific downstream tasks by providing task-specific input-output examples.

## Evaluation
***
### Metrics
In order to evaluate the model's performance we used the following metrics:
* **F1 score** - a harmonic mean of precision and recall.
$$\text{{F1}} = \frac{{2*\text{{Precision}}*\text{{Recall}}}}{{\text{{Recall}} + \text{{Precision}}}}$$

* **Exact-match** - a measure of the exact string matching between the predicted answer and the ground truth one.
$$\text{{EM}} = {\text{{Prediction}} == \text{{Ground \ truth}}}$$

* **Rouge1(Unigram Overlap)** - a measure of the overlap between unigrams (single words) in the reference and generated titles, indicating the similarity in word usage.
$$\text{{Rouge-1}} = \frac{{\text{{Number \ of \ overlapping \ unigrams \ between \ the \ reference \ and \ generated \ titles}}}}{{\text{{Number \ of \ unigrams \ in \ the \ reference \ title}}}}$$

* **Rouge-2 (Bigram Overlap)** - a measure of the overlap between consecutive pairs of words (bigrams) in the reference and generated titles, capturing the degree of phrase-level similarity.
$$\text{{Rouge-2}} = \frac{{\text{{Number \ of \ overlapping \ bigrams \ between \ the \ reference \ and \ generated \ titles}}}}{{\text{{Number \ of \ bigrams \ in \ the \ reference \ title}}}}$$

* **Rouge-Sum** - a combination of Rouge-1 and Rouge-2 scores into a single score, providing an overall measure of the similarity between the reference and generated titles.
$$\text{{Rouge-Sum}} = \frac{{2 \times \text{{Rouge-1}} \times \text{{Rouge-2}}}}{{\text{{Rouge-1}} \ \text{{+}} \ \text{{Rouge-2}}}}$$

* **Gen Len (Generated Title Length)** - the length (number of words) of the generated title, indicating its brevity or verbosity.
$$\text{{Gen \ Len}} = \text{{Length \ of \ the \ generated \ title}}$$
***

### Model's performance

<p align="center">
    <img  width="890" src="https://github.com/Severyn12/arrhythmia_detection/assets/73779019/b63b593b-75af-4dac-bdf7-5980bad7416d" alt="Image" />
</p>

Above, we can observe plots that demonstrate us the training history for text summarization task. The poorest performance was observed in samples where the article content might have been in violation. The presence of brutality or negative thoughts degrades the model's performance. Such situations is possible because the T5 model is sensitive to cruel contexts.
***

<p align="center">
    <img  width="880" src="https://github.com/Severyn12/arrhythmia_detection/assets/73779019/42f3d444-5f9a-499b-addf-ae3d3489c159" alt="Image" />
</p>

Above we can observe how the values of different metrics were evolving during the training stage for QA task. In order to provide additional clarity, it is worth mentioning that the ExactMatch and F1 scores are expressed as percentages. From the above plots and metrics, we can conclude that the fine-tuned T5 model showed quite good performance on the question-answering task.
***

## Real-example testing
***
### Text summarization task

<p align="center">
    <img  width="800" src="https://github.com/Severyn12/arrhythmia_detection/assets/73779019/9ea67136-7d1e-4144-9574-dd0a0f1d1069" alt="Image" />
</p>

***

### QA task

<p align="center">
    <img  width="800" src="https://github.com/Severyn12/arrhythmia_detection/assets/73779019/add42f81-0ade-4010-b99d-bd8c33ef632a" alt="Image" />
</p>

***

## Credits

[Markiian Tsalyk](https://www.linkedin.com/in/markiian-tsalyk-193758224/)

[Severyn Peleshko](https://www.linkedin.com/in/severyn-peleshko-163a71225/)
***
## License
[MIT](https://github.com/Severyn12/T5-LimitsExploring/blob/main/README.md)
